{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# European Soccer Database\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#wrangling\">Data Wrangling</a></li>\n",
    "<li><a href=\"#eda\">Exploratory Data Analysis</a></li>\n",
    "<li><a href=\"#conclusions\">Conclusions</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "As an average european male citizen I've always been interested in \"football\". In fact, I've done a fair bit of online football betting with not much success. It may well be that I was letting myself to passion as opposed to data. This project therefore represents a good opportunity to take more informed decissions should I decide to bet in the future.\n",
    "\n",
    "The database is available at [Kaggle](https://www.kaggle.com/hugomathien/soccer). It consists of a sqlite database that contains eight different tables. The amount of detail in the database is overwhelming and for this project only a subset of the tables will be used. \n",
    "\n",
    "Before starting a discussion on what information is relevant for this project, let's first pose the questions and then discuss what parts of the database will be useful to answer them.\n",
    " > Since there is information on winning probability assigned by the bookmaker, it may be worth answering whether matches where there is a clear favourite show different statistics from those other matches where winning probabilities are more evenly distributed. **Does the fact that we know whether there is a favourite in a match increase our chances of predicting some other statistic about the game?**\n",
    "\n",
    " > It seems to me that the number of goals in any given stage will be directly related to how far into the season a match is played. At the beginning of the season there are generally some new players that have not adapted yet, also players are not yet in shape. At the end of the season players are generally tired after playing the whole season. So my question is **Are there more goals for stages that take place around mid-season?**\n",
    "\n",
    " > Also an 'a priori' thought that occurs to me is that when the probabilities for each result are not assigning a clear favourite, then to me (no data analysis yet...) that represent a totally random process where probabilities can be calculated with the information contained in the database. If for example the probability for home win was 40%. **Would an strategy of betting for home win when it pays > 1/0.4 be a successful strategy?**\n",
    " \n",
    " > Lastly, if I was the new president of an aspiring team with enough money. **Is it worth investing in a top10 scorer?** or in other words **Do top scorers play in the most successful teams**\n",
    "\n",
    "In order to answer these questions above we then need the following tables from the database:\n",
    "* **Country**. This table will enable comparing results by country name as opposed to country id\n",
    "* **Match**. This table contains the bulk of data for this project and it will be used to answer every question\n",
    "* **Player**. This table will help us answer last question\n",
    "* **Team**. This table, again will help us answer last question and support some of the assertions in the analysis below   \n",
    "\n",
    "I have deliverately not included the following tables\n",
    "\n",
    "* **League**. The database only contains one league per country, so this table does not add any extra information\n",
    "* **Player_Attributes**: This database contains information about player skill. This table does not add any information to answer the questions above.\n",
    "* **Team_Attributes**: Similarly, this table does not add any useful information that could be used to answer the questions above.\n",
    "\n",
    "The idea then is to query the database to extract all the useful information. Then doing all data wrangling process to have the data in the most organised way possible. To answer the first three questions, the **match** table contains most of the information required. However it will be seen that information from **Country** is also required.  \n",
    "\n",
    "A list of the Python modules that will be used can be seen in the excerpt below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, worth mentioning that I've copied from [here](https://www.kaggle.com/jiezi2004/the-beautiful-game-1-data-preparation/notebook) the following two functions that will help me parse XML data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTags(xMLcolumnNm, matches):\n",
    "    elemList = []\n",
    "    # iterate each row in the XML column\n",
    "    for index, row in matches[pd.notnull(matches[xMLcolumnNm])].iterrows():\n",
    "        # read in xml data\n",
    "        tree = ET.ElementTree(ET.fromstring(row[xMLcolumnNm]))\n",
    "        for elem in tree.iter():\n",
    "            elemList.append(elem.tag) # append tag name\n",
    "\n",
    "    # remove duplicates of tag names\n",
    "    return list(set(elemList))\n",
    "def parseXMLData(xMLcolumnNm, matches):\n",
    "    tags = getTags(xMLcolumnNm,matches) # get a list of all tags\n",
    "       \n",
    "    tagLists = {} # host all other tags\n",
    "    pos = []\n",
    "    otherList = {'match_id':[], 'pos_x':[], 'pos_y':[]} # host match id\n",
    "    \n",
    "    for tag in tags:\n",
    "        tagLists[tag] = [] # initiate tag lists   \n",
    "        \n",
    "    for index, row in matches[pd.notnull(matches[xMLcolumnNm])].iterrows():\n",
    "        game_id = row['id'] # this helps identify match\n",
    "        # rea-in XML data\n",
    "        tree = ET.ElementTree(ET.fromstring(row[xMLcolumnNm]))\n",
    "        root = tree.getroot()  \n",
    "        \n",
    "        for event in root.findall('value'):\n",
    "            otherList['match_id'].append(game_id)\n",
    "            for tag in tags:\n",
    "                if(event.find(tag) is None):\n",
    "                    tagLists[tag].append(None)\n",
    "                else:\n",
    "                    tagLists[tag].append(event.find(tag).text) \n",
    "                    \n",
    "            # get position information\n",
    "            if(event.find('coordinates') is None): \n",
    "                pos.append(None)\n",
    "                pos.append(None)\n",
    "            else:  \n",
    "                for value in event.findall(\"coordinates/value\"):\n",
    "                    pos.append(value.text)\n",
    "                    \n",
    "    otherList['pos_y'] = pos[1::2]  # Elements from list1 starting from 1 iterating by 2\n",
    "    otherList['pos_x'] = pos[0::2]  # Elements from list1 starting from 0 iterating by 2\n",
    "            \n",
    "    xmlInfo = {**otherList, **tagLists}\n",
    "    return pd.DataFrame(xmlInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, everything is ready to start getting data from the database. In order to fetch data we use the module sqlite3 that will help querying the data base with SQL grammar. Data from the database will be used to create pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with sqlite3.connect('./database.sqlite') as con:\n",
    "    df_countries = pd.read_sql_query(\"SELECT * from Country\", con)\n",
    "    df_matches = pd.read_sql_query(\"SELECT * from Match\", con)\n",
    "    df_teams = pd.read_sql_query(\"SELECT * from Team\", con)\n",
    "    df_players = pd.read_sql_query(\"SELECT player_api_id, player_name FROM Player;\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wrangling'></a>\n",
    "## Data Wrangling\n",
    "\n",
    "### General Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all data is organised in dataframes, we are ready to start the data wrangling phase. The idea is to make changes to the original dataframes so that only relevant information is used. As explained in the introduction, the first three questions refer to general statistics about matches in general. Information on players or specific teams will not add relevant information. Therefore the main piece of data that I'll be using will be data contained in dataframe **df_matches**. Also, data will be more readable if the country appeared by name, as opposed to id. This means that a JOIN operation needs to be performed between df_matches and df_countries so all the information can be found under the same dataframe. The resulting dataframe will contain all information required to answer 3 out of our 4 questions, so **df_main** will be the name for this dataframe\n",
    "\n",
    "### Operations on dataframes to obtain a clean *df_main*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data in df_countries is quite simple. It contains a mapping between country id and country name. For the purpose of this analysis only the three major (England, Italy and Spain) leagues will be chosen (Warning: Which are the major leagues it's a debatable topic, so this represents a personal opinion).  \n",
    " > * Filter df_countries to get only those countries I'm interested in.  \n",
    "\n",
    "Once df_countries is ready, merge it with df_matches to form main_df. Please note, that the JOIN operation on these two dataframes will be an INNER JOIN. Therefore countries in df_matches that I'm not interested in, will be dropped after the JOIN operation.\n",
    " > * Perform an INNER JOIN  \n",
    " > * Rename the column id_y to id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9097, 117)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_countries.query('name in [\"England\", \"Italy\", \"Spain\"]', inplace = True)\n",
    "main_df = df_countries.merge(df_matches, left_on= 'id', right_on='country_id')\n",
    "# Keep the id from matches, as we will need it for later JOINs\n",
    "main_df.rename(columns={'id_y':'id'},inplace=True)\n",
    "main_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that our main dataframe contains a very large number of columns. After inspection it can be seen that there are many that can be pruned.  \n",
    "For example it contains information about coordenates of players in the field. This does not bring any added benefit to this analysis. So let's remove those columns that contain coordinates. These are defined as home_playerX# home_playerY#, away_playerX# away_playerY#. Also individual footballers that played that game are of no interest so we can drop those as well. These ids are in the shape of home_player_#, away_player_#\n",
    "\n",
    "There are still more columns we could get rid of... for example columns with betting odds. There are a number of 10 bookmakers in this dataframe, each of them using 3 columns for home, draw, away odds. It's understood that different betting companies will assign similar probabilities to the same sporting events. Let's quickly assert our understanding by comparing the average probabilities that different bookmakers have assinged to home win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a slice of the original dataframe containing only betting odds\n",
    "bookies = df_matches.iloc[:,-10*3:]\n",
    "bookies['homeWinSpread'] = np.repeat(0,len(bookies.index))\n",
    "bookies.dropna(inplace=True) # In order to get spread bewtween bookies we don't care whether there are a few missing games\n",
    "for bookieNum in range(1,10):\n",
    "    # Compare probability deviations from the first bookmaker in the dataframe\n",
    "    bookies['homeWinSpread'] += abs((bookies.iloc[:,3*bookieNum]/bookies.iloc[:,0]) - 1) \n",
    "bookies['homeWinSpread'] /= 0.09 # Divide by 9 to calculate average multiply by 100 to get percentage spread\n",
    "plt.hist(bookies['homeWinSpread'],range(0,30,5));\n",
    "plt.xlabel('Average difference in % per game');\n",
    "plt.ylabel('Number of occurences');\n",
    "plt.title('Differences in assigned home win probabilities');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed in the histogram above that probabilities assigned to home wins are on average *mostly* within 5% of each other. Therefore it's safe to get rid of all the bookmakers information BUT one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9097 entries, 0 to 9096\n",
      "Data columns (total 20 columns):\n",
      "name                9097 non-null object\n",
      "id                  9097 non-null int64\n",
      "season              9097 non-null object\n",
      "stage               9097 non-null int64\n",
      "date                9097 non-null object\n",
      "home_team_api_id    9097 non-null int64\n",
      "away_team_api_id    9097 non-null int64\n",
      "home_team_goal      9097 non-null int64\n",
      "away_team_goal      9097 non-null int64\n",
      "goal                9093 non-null object\n",
      "shoton              9093 non-null object\n",
      "shotoff             9093 non-null object\n",
      "foulcommit          9093 non-null object\n",
      "card                9093 non-null object\n",
      "cross               9093 non-null object\n",
      "corner              9093 non-null object\n",
      "possession          9093 non-null object\n",
      "B365H               9090 non-null float64\n",
      "B365D               9090 non-null float64\n",
      "B365A               9090 non-null float64\n",
      "dtypes: float64(3), int64(6), object(11)\n",
      "memory usage: 1.5+ MB\n",
      "\n",
      "\n",
      "Are there any duplicate lines in this dataframe: False\n"
     ]
    }
   ],
   "source": [
    "# id_x, league_id and country_id can be removed after the JOIN operation as they are no longer required.\n",
    "redundantColumnList = ['id_x','league_id', 'country_id', 'match_api_id']\n",
    "# Also, analysing information on players will be too time consuming, so player attributes or positions won't be explored\n",
    "listToDrop = [('{}_player_{}{}'.format(side,coor,num),'{}_player_{}'.format(side,num) ) \n",
    "              for side in ['home','away'] for coor in ['X','Y'] for num in range(1,12)]\n",
    "listToDrop = [x[0] for x in listToDrop ] + list(set([x[1] for x in listToDrop ])) + redundantColumnList\n",
    "# Also, there are a total of 10 bookmakers... get only the first one\n",
    "listToDrop = list(df_matches.columns[-9*3:]) + listToDrop\n",
    "main_df.drop(columns=listToDrop, inplace =True)\n",
    "main_df.info()\n",
    "print ( \"\\n\\nAre there any duplicate lines in this dataframe: {}\".format(main_df.duplicated().any()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the information above we can see that there are no duplicated games, so that's good and nothing to do on that front.\n",
    "\n",
    "However, there are matches that are missing data. Looking at the numbers it can be observed that the amount of missing information is small compared to the overall number of entries.\n",
    "\n",
    "There are genearlly two ways to proceed with missing dat. We either make up the information or remove those rows. Since the number of lines with missing information is only a very small percentage of the whole, and also to ease analysis let's drop those rows.\n",
    "\n",
    "Also, it seems that there are columns that are represented with the wrong type. For exmaple goal, foulcommit or card... This is because these columns contain more information in XML format. We will need to parse those columns, obtain new dataframes and remove these columns from our main dataframe since their information will be located somewhere else. Please note that data on *shot on, shot off* and *cross* is not relevant for our analysis and it won't be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>season</th>\n",
       "      <th>stage</th>\n",
       "      <th>date</th>\n",
       "      <th>HT_id</th>\n",
       "      <th>AT_id</th>\n",
       "      <th>HT_goal</th>\n",
       "      <th>AT_goal</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>England</td>\n",
       "      <td>1729</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-08-17 00:00:00</td>\n",
       "      <td>10260</td>\n",
       "      <td>10261</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.29</td>\n",
       "      <td>5.5</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name    id     season  stage  ...   AT_goal  B365H  B365D  B365A\n",
       "0  England  1729  2008/2009      1  ...         1   1.29    5.5   11.0\n",
       "\n",
       "[1 rows x 12 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.dropna(inplace=True)\n",
    "goalInfo = parseXMLData('goal',main_df)\n",
    "foulsInfo = parseXMLData('foulcommit',main_df)\n",
    "cardsInfo = parseXMLData('card',main_df)\n",
    "cornerInfo = parseXMLData('corner',main_df)\n",
    "possessionInfo = parseXMLData('possession',main_df)\n",
    "main_df.drop(columns=[\"goal\",\"shoton\",\"shotoff\",\"foulcommit\",\"card\",\"cross\",\"corner\",\"possession\"],inplace=True)\n",
    "main_df.rename(columns={'home_team_api_id':'HT_id', 'away_team_api_id':'AT_id', 'home_team_goal':'HT_goal', \n",
    "                        'away_team_goal':'AT_goal'}, inplace=True)\n",
    "main_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Wrangling on XML-formatted columns\n",
    "The first line of our main_df dataframe displayed above shows the cleaning process results. Also the match above will be useful to verify whether the information parsed with the XML parser is trustworthy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id  HT_id  AT_id\n",
      "0  1729  10260  10261\n",
      "\n",
      "\n",
      "\n",
      "      id  team_api_id       ...           team_long_name team_short_name\n",
      "25  3457        10260       ...        Manchester United             MUN\n",
      "26  3458        10261       ...         Newcastle United             NEW\n",
      "\n",
      "[2 rows x 5 columns]\n",
      "\n",
      "\n",
      "\n",
      "      player_api_id      player_name\n",
      "2288          24148  Darren Fletcher\n",
      "4592          38807     James Milner\n",
      "8067          37799  Obafemi Martins\n",
      "9333          24154       Ryan Giggs\n"
     ]
    }
   ],
   "source": [
    "print (main_df[main_df['id'] == 1729].loc[:,['id','HT_id', 'AT_id']])\n",
    "print (\"\\n\\n\")\n",
    "print (df_teams.query('team_api_id in [10260,10261]'))\n",
    "print (\"\\n\\n\")\n",
    "print (df_players.query('player_api_id in [37799,38807,24148,24154]'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to results shown above this game was  \n",
    "Manchester Ud. vs Newcastle Results 1-1 Players participating: Fletcher, Milner, Martins and Giggs\n",
    " \n",
    "Let's check which of those values are important by looking at what happened in reality. Information can be found [here](\n",
    "http://news.bbc.co.uk/sport1/hi/football/eng_prem/7551173.stm)\n",
    "\n",
    "That link shows that only *player1* information is useful as it represents the scorer. Please note that player1 is represented by an ID. It will help readability to include the name instead of the ID. In order to do so, we will need to perform a JOIN operation between the goal dataframe (extracted from the XML info in matches table) and df_players. Also note that this new dataframe will help answer **question 4** so let's drop all other columns.  \n",
    "The information that this dataframe contains (goalInfo) is already present in dF_main (just add home goals and away goals). However the cleaning operation on this dataframe will be useful to answer question 4. So we won't be looking at this dataframe for some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>player_api_id</th>\n",
       "      <th>player_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1729</td>\n",
       "      <td>37799</td>\n",
       "      <td>Obafemi Martins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id  player_api_id      player_name\n",
       "0      1729          37799  Obafemi Martins"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goalInfo = goalInfo[['match_id','player1']].dropna()\n",
    "goalInfo['player1'] = goalInfo.player1.astype(int)\n",
    "# Now add this information by doing a JOIN\n",
    "goalInfo = goalInfo.merge(df_players,left_on='player1', right_on='player_api_id')\n",
    "goalInfo.drop(columns='player1',inplace=True)\n",
    "goalInfo.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe above contains lines that are duplicated so \n",
    " > sum(goalInfo.duplicated()) != 0\n",
    " \n",
    " However this is most likely not a problem with the data itself... rather the most plausible explanation is that the same player scored twice in the same match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two XML-parsed dataframes that will be inspected are foulsInfo and cardsInfo. For these dataframes, we are only interested in the number of them per match. The caveat on cards, is that they can take three different values, that is 'y', 'y2' or 'r'. So let's start with fouls that look simpler and calculate the number of fouls per game. For cards let's group them first and see what the resulting dataframe looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42853 entries, 0 to 42852\n",
      "Data columns (total 2 columns):\n",
      "match_id     42853 non-null int64\n",
      "card_type    42366 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 669.7+ KB\n"
     ]
    }
   ],
   "source": [
    "foulsInfo.drop(columns=[x for x in foulsInfo.columns if x not in ['match_id','id']],inplace=True)\n",
    "foulsInfo = foulsInfo.groupby('match_id').count()\n",
    "cardsInfo.drop(columns=[x for x in cardsInfo.columns if x not in ['match_id','card_type']],inplace=True)\n",
    "cardsInfo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are missing values of card_type in this dataframe. This time, we will follow a different approach, as I don't want to get rid of any game due to missing information on cards. Therefore calculate the probability of a card taking each value (y, y2,r), create a sample and use it to fill in those missing values.\n",
    "\n",
    "Then prepare the resulting dataframe to be merged with main_df. It should result in three new columns in main_df one for each of the card types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cardsByType = cardsInfo.groupby('card_type').count()\n",
    "probRed = cardsByType.loc['r','match_id']/sum(cardsByType['match_id'])*100\n",
    "probYellow = cardsByType.loc['y','match_id']/sum(cardsByType['match_id'])*100\n",
    "probSecondYellow = cardsByType.loc['y2','match_id']/sum(cardsByType['match_id'])*100\n",
    "# Based on the probabilities above, create a list with as many items as missing values in cards dataframe\n",
    "cardTypeDummyList = [ 'y' if x > (probSecondYellow+probRed) else 'y2' \n",
    "                          if (x > probRed and x <= (probSecondYellow+probRed)) else 'r' for x in [random.randint(0,101) \n",
    "                          for _ in range(0, cardsInfo[cardsInfo['card_type'].isna()].count().match_id) ]]\n",
    "# Fill the original dataframe with the random values calculated\n",
    "cardsInfo.loc[cardsInfo['card_type'].isna(),'card_type'] = cardTypeDummyList\n",
    "# Add a new column to count how many of each type\n",
    "cardsInfo['helpColumn'] = np.repeat(1,len(cardsInfo.index))\n",
    "cardstmp = cardsInfo.groupby(['match_id','card_type']).count()\n",
    "# Use the previous information to create a dataframe where number of card type per match is used\n",
    "# If there are missing values fill them with 0 as it means that no card of that type has been shonw\n",
    "# for that game\n",
    "cardsInfo = pd.DataFrame(index=cardstmp.unstack().index,columns=['y','y2','r'])\n",
    "cardsInfo['y'] = cardstmp.unstack()['helpColumn','y'].fillna(0).astype(int)\n",
    "cardsInfo['y2'] = cardstmp.unstack()['helpColumn','y2'].fillna(0).astype(int)\n",
    "cardsInfo['r'] = cardstmp.unstack()['helpColumn','r'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last two XML-parsed dataframes... From corner get only the number of them in the game. From possession get the home and away possession percentages and prepare the dataframe to be merged to df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From corners we may want to keep the following columns match_id, player1, team\n",
    "cornerInfo.drop(columns=[x for x in cornerInfo.columns if x not in ['match_id','player1','team']],inplace=True)\n",
    "cornerInfo = cornerInfo.groupby(['match_id']).count().drop(columns=['team'])\n",
    "# From possession keep match_id, awaypos and drop all rows that don't contain possession infomration\n",
    "possessionInfo.dropna(subset=['awaypos', 'homepos'],inplace=True)\n",
    "possessionInfo.drop(columns=[x for x in possessionInfo.columns if x not in ['match_id','awaypos','homepos']],inplace=True)\n",
    "# Since there are a few possession readings per game... and all seem similar, calculate the average per game\n",
    "possessionInfo.awaypos = possessionInfo.awaypos.astype(float)\n",
    "possessionInfo.homepos = possessionInfo.homepos.astype(float)\n",
    "possessionInfo = possessionInfo.groupby('match_id').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the XML-parsed dataframes have now been processed and are ready to be incorporated to df_main. Perform all JOIN operations on these different dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6220 entries, 0 to 9096\n",
      "Data columns (total 19 columns):\n",
      "id            6220 non-null int64\n",
      "name          6220 non-null object\n",
      "season        6220 non-null object\n",
      "stage         6220 non-null int64\n",
      "date          6220 non-null object\n",
      "HT_id         6220 non-null int64\n",
      "AT_id         6220 non-null int64\n",
      "HT_goal       6220 non-null int64\n",
      "AT_goal       6220 non-null int64\n",
      "B365H         6220 non-null float64\n",
      "B365D         6220 non-null float64\n",
      "B365A         6220 non-null float64\n",
      "numFouls      6220 non-null int64\n",
      "y             6220 non-null float64\n",
      "y2            6220 non-null float64\n",
      "r             6220 non-null float64\n",
      "numCorners    6220 non-null float64\n",
      "awaypos       6220 non-null float64\n",
      "homepos       6220 non-null float64\n",
      "dtypes: float64(9), int64(7), object(3)\n",
      "memory usage: 971.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>season</th>\n",
       "      <th>stage</th>\n",
       "      <th>date</th>\n",
       "      <th>HT_id</th>\n",
       "      <th>AT_id</th>\n",
       "      <th>HT_goal</th>\n",
       "      <th>AT_goal</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>numFouls</th>\n",
       "      <th>y</th>\n",
       "      <th>y2</th>\n",
       "      <th>r</th>\n",
       "      <th>numCorners</th>\n",
       "      <th>awaypos</th>\n",
       "      <th>homepos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1729</td>\n",
       "      <td>England</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-08-17 00:00:00</td>\n",
       "      <td>10260</td>\n",
       "      <td>10261</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.29</td>\n",
       "      <td>5.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>27</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>45.25</td>\n",
       "      <td>54.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id     name     season  stage   ...       r  numCorners  awaypos  homepos\n",
       "0  1729  England  2008/2009      1   ...     0.0        12.0    45.25    54.75\n",
       "\n",
       "[1 rows x 19 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df = main_df.merge(foulsInfo,left_on='id',right_index=True).rename(columns={'id_y':'numFouls'}).drop(columns=['id_x'])\n",
    "main_df = main_df.merge(cardsInfo,left_on='id',right_index=True,how='left')\n",
    "main_df = main_df.merge(cornerInfo,left_on='id',right_index=True,how='left').rename(columns={'player1':'numCorners'})\n",
    "main_df = main_df.merge(possessionInfo,left_on='id',right_index=True,how='left')\n",
    "# Fill in NA positions with valid values\n",
    "main_df.loc[main_df['awaypos'].isna(),'awaypos'] = 50\n",
    "main_df.loc[main_df['homepos'].isna(),'homepos'] = 50\n",
    "main_df.loc[main_df['numCorners'].isna(),'numCorners'] = 0\n",
    "main_df.loc[main_df['y'].isna(),'y'] = 0\n",
    "main_df.loc[main_df['y2'].isna(),'y2'] = 0\n",
    "main_df.loc[main_df['r'].isna(),'r'] = 0\n",
    "print(main_df.info())\n",
    "main_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's summarize the steps taken to get all necessary dataframes that will help answer questions posed.\n",
    "* Raw tables from the SQL database were obtained and parsed to dataframes\n",
    "* Dataframes containing information on countries and matches were merged to form main_df\n",
    "* After doing some cleaning and peeking at data types, it was noted that some columns contained more info in XML format\n",
    "* These columns were in turn parsed to other dataframes containing info on goals, fouls, cards, corners and possession\n",
    "* XML-parsed goals dataframe was merged with players table and will help answer question 4.\n",
    "* The rest of XML-parsed dataframes were processed and merged back to main_df\n",
    "\n",
    "We are then now ready to develop answers for the questions posed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "## Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## Conclusions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
